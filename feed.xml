<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://ian-yang-02.github.io//feed.xml" rel="self" type="application/atom+xml" /><link href="https://ian-yang-02.github.io//" rel="alternate" type="text/html" hreflang="en" /><updated>2025-06-08T03:09:29+00:00</updated><id>https://ian-yang-02.github.io//feed.xml</id><title type="html">blank</title><subtitle></subtitle><entry><title type="html">welcome to the token of the real</title><link href="https://ian-yang-02.github.io//thoughts/2025/pomo-llms/" rel="alternate" type="text/html" title="welcome to the token of the real" /><published>2025-05-10T00:00:00+00:00</published><updated>2025-05-10T00:00:00+00:00</updated><id>https://ian-yang-02.github.io//thoughts/2025/pomo-llms</id><content type="html" xml:base="https://ian-yang-02.github.io//thoughts/2025/pomo-llms/"><![CDATA[<p>A few months ago I was in a lab meeting at Georgia Tech when a PhD student said something that I thought was a bit interesting. He expressed that “the well has been poisoned,” referring to the fact that we can no longer guarantee the purity (from AI) of any newly written text. Though not necessarily a novel idea, this is a worrying prospect - is it true that AI/LLM generated text is so pervasive that it has become truly inexcapable?</p>

<p>There’s so much tense interplay between AI-generated text and natural human language; each day there are hundreds of funny posts about professional slip-ups with LLMs, numerous college professors trying to catch students using ChatGPT, an <i>n</i>-th paper about how _PO beat a “human” benchmark by 1.8%, etc.</p>

<p>In a world where the zeitgeist is so heavily defined by the role of AI and text (when in recent history has the general public cared so much about language?), it seems only natural that we should wonder about the semiotic implications and consequences of language technologies.</p>

<h3><b>on Baudrillard</b></h3>

<p>In his seminal work <i>Simulacra and Simulation</i>, Jean Baudrillard examines the relationships between the signifiers and signified in modern society. Traditional semiotics finds that the signifier and the signified are components of a sign - which itself is an abstract or material representation of some concept that we can ascribe meaning to.</p>

<blockquote>
  <p>“Nothing is a sign unless it is interpreted as a sign” - Charles Sanders Peirce</p>
</blockquote>

<p>A signifier then is the understandable form that a sign takes - a word (itself a combination of letters), an image, sound, etc., and the signified is the concept which a sign then represents.</p>

<p>Baudrillard, however, posits that the stable relationship between the signifier and the signified has grown more and more unclear, leading to a state where the grounding of a sign to a concrete world object or concept becomes increasingly arbitrary, or may not exist at all. This blurriness between signs and reality defines Baudrillard’s conception of simulacra; the signifiers of concepts within the world grow detached from their signified, and adopt meaning that is separated from any original “reality.” At some point, the relationship between signifiers and the signified inverses - the precession of simulacra, where the map not only precedes the territory but generates it. In turn, these signs produce “hyperreality” - a state in society where simulation of reality via simulacra precedes a true reality, where the signs that model concepts become stand-ins for the concepts themselves.</p>

<p><b><u>LLM Hyperreality</u></b></p>

<p>Here lies the crux of the problem: at what point can we argue that the language generated by LLMs has become a simulacrum for true human language? I believe it can be argued that we are increasingly building the hyperreality in which AI-generated text continuously displaces and precedes human text. The Dead Internet Theory (a well-known conspiracy theory) already crudely touches on this idea, arguing that the majority of internet interactions and activity are by bots that manipulate social media algorithms. Now, with the advent of LLMs and increasingly powerful Generative AI tools, this prospect becomes more and more likely. It seems that almost all online activity could be marked by the influence of LLMs, and each subsequent interaction, generation, or post more deeply cements the hyperreality built by the simulacrum that is artificial text. This also may lead to what Baudrillard calls <i>implosion</i>, where the nuance and meaning of human language gets lost, plagued by the loss of a stable referent as AI text becomes more and more prevalent.</p>

<p>At some point in the past few years, “ChatGPT” has become a stand-in for “LLM”. To people who are not particularly versed in the NLP space (or who don’t keep with with emerging technologies), it seems like other variants of LLMs (Gemini, Claude, Llama, etc.) become bleached to a generic “ChatGPT”. I find this to be notably different from traditional brand genericide (“Google” for “Internet search”, for example) because to the general public, “ChatGPT” encompasses the totality of the signified. ChatGPT as a signifier has gained its own autonomy and can continuously perpetuate its own automony via hyperreality. For so many people now, LLMs themselves do not even exist outside of ChatGPT; the sign of ChatGPT itself has lost its stable signified and now encompasses the totality of the concept.</p>

<p>Baudrillard finds that there are four stages of simulacra. The third stage (the “order of sorcery”) is a state where the simulacrum becomes a copy without a reality, while maintaining the mimicry of something real. I would argue that the state of the digital world with LLMs has reached this stage. AI-generated text promises to be faithful to human language, and often will represent it in a way that seeks to convince a human reader that it is in fact the same. The more generated text that exists, that permeates into our every day encounters with language, the more the simulacra builds upon the hyperreality that we exist in online. In fact, the LLM-generated text no longer is a true faithful representation of the human language referents; LLMs hallucinate, craft incorrect answers, and draw false conclusions, acting as a representative copy of human text whie exisiting independently, without a grounding in reality. The meaning that we ascribe to this language cannot be rooted in any true reality, as the signifier has uprooted the signified.</p>

<p><b><u>Latent Spaces</u></b></p>

<p>I was also curious about how we may understand the operational mechanics of these models under the lens of hyperreality. Latent spaces are lower dimensional spaces that encode representations of higher dimensional data. In LLMs, the vast, high-dimensional text data is compressed to a lower dimensional latent space where data is more compact and more easily manipulated, allowing us to search for patterns or novel characteristics in the distribution. These kinds of patterns include things like semantic relationships, conceptual proximity, and stylistic patterns. However, these encodings and patterns are merely internal signifiers, and their relationships to external, concrete signified is often complex. Are these latent encodings direct representations of real-world concepts, or do they just signify patterns that are purely internal to training set, which is itself a high dimensional collection of signifiers? This begs the question of whether LLMs are constructing their output from a simulated understanding, creating texts that are simulations derived from these embedded, abstract signifiers. This self-referential system generates outputs that can appear more “real” than real, a perfect, smoothed-out version of language that masks its own lack of grounding.</p>

<p><b><u>The Well in the Desert of the Real</u></b></p>

<p>In <i>Simulacra and Simulation</i>, Baudrillard also introduces the concept of the <b>desert of the real</b>, describing the state of our reality where we are increasingly surrounded by the hyperreal, and where encounters with authentic reality become more and more scarce. He argues that we exist now in this desert where everything is simulated, just copies of copies, signifiers of signifiers. In many ways, our digital world is becoming such a desert, where we are surrounded by AI-generations of generations of generations.</p>

<p>One of my favorite books of all time is Antoine de Saint-Exupéry’s <i>The Little Prince</i>. In it, there is this wonderful little quote:</p>

<blockquote>
  <p>“What makes the desert beautiful,” said the little prince, “is that somewhere it hides a well.”</p>
</blockquote>

<p>In our modern desert of the real, this well represents unfettered and untouched raw human expression via language, grounded in the human experience, truth, and meaning. The well represents the value that our humanity imparts on the words that we say, and the text that we write. If the metaphorical well truly has been poisoned, as the PhD student expressed, then the well itself has become a simulacrum for the human expression. In the hyperreal desert, LLMs hold the power to continuously and infinitely build these simulated wells.</p>

<p>Each might appear to offer refreshment, knowledge, or connection, engaging in a seduction where their fluency and responsiveness charm us into accepting their outputs as equivalent, or even superior, to human interaction. Yet collectively, they risk drawing us further into the hyperreal. If the desert of our digital world becomes populated by countless, easily accessible, yet artificial sources, does the inherent value of seeking out a genuine well diminish? The question then becomes not only whether we can distinguish the authentic from the artificial, but whether the sheer volume and sophistication of the simulacra will fundamentally alter our relationship with human-generated language itself.</p>

<h3><b>and Derrida?</b></h3>

<p>Still thinking! Check back later for more :D</p>

<!--- Interesting things to write about 
Derrida deconstructing binaries between LLM/Human Generated Text (how can one exist without the other, how do they interact, what exists in the 'differance' between them?)
 --->]]></content><author><name></name></author><summary type="html"><![CDATA[on Baudrillard, Derrida, and language models]]></summary></entry><entry><title type="html">applying for PhD programs and the GRFP</title><link href="https://ian-yang-02.github.io//thoughts/2025/graduate-school/" rel="alternate" type="text/html" title="applying for PhD programs and the GRFP" /><published>2025-05-04T00:00:00+00:00</published><updated>2025-05-04T00:00:00+00:00</updated><id>https://ian-yang-02.github.io//thoughts/2025/graduate-school</id><content type="html" xml:base="https://ian-yang-02.github.io//thoughts/2025/graduate-school/"><![CDATA[<p><i>If you are applying for PhD programs and/or the GRFP and want to chat don’t hesitate to <a href="mailto:iyang30@uw.edu">reach out</a> (especially if you belong to a traditionally underrepresented group in higher education!!)</i></p>

<h3><b>Background</b></h3>

<p>Beginning in September 2025, I’ll be joining the University of Washington (UW) iSchool as a PhD student in Information Science, where my research will also be supported by the NSF GRFP.</p>

<p>It took me two cycles to get to this point, and across the past couple of years and submitting 44 (!!) applications, I’ve developed some thoughts and opinions about applying for graduate schools (specifically PhD programs in Computer Science, and even more specifically in natural language processing [NLP]).</p>

<p>These thoughts are likely heavily skewed towards US-based CS/NLP programs, so if you are outside of these domains (or even if you are looking to study NLP), please don’t take a dogmatic stance towards any of this.</p>

<p>Some general things to keep in mind:</p>
<ul>
  <li>I’m a US Citizen and applied from the US</li>
  <li>I went to a “top” undergraduate school for CS</li>
  <li>I applied directly out of undergrad, as well as during a gap year</li>
  <li>I don’t have a Master’s degree</li>
</ul>

<h3><b>PhD Applications</b></h3>

<p>Across two cycles of PhD applications I applied to 44 different programs - 19 for 2023-2024, and 25 for 2024-2025. Interestingly, the only InfoSci program I applied to was the UW iSchool; the rest were pure Computer Science programs or at least housed in the CS schools/departments (this is mostly relevant for CMU, where there are seven separate PhD programs within the SCS).</p>

<p><b><u>Choosing Where to Apply</u></b></p>

<p>Typically, when you are deciding to apply for PhD programs, you should have somewhat of an idea of what you want to study. You don’t necessarily need to have an outlined research plan, but you should be able to have a discussion about why you’re interested in pursuing a PhD in that specific topic. In my case, I knew at the time that I wanted to study the societal underpinnings of language technologies, and how to both evaluate existing models and improve their sociocultural alignment in the future.</p>

<p>Because I have a relatively concrete idea of what I want to pursue during my PhD (at least for the beginning), I took a good amount of time to research what faculty at which schools were working on similar topics. This ranged from looking up what I was interested in on Google Scholar and seeing what popped up (“LLM Alignment”, “Sociocultural NLP”, and so forth) to browsing through conference proceedings at well known NLP (EMNLP, NAACL, etc.), ML (ICML, ICLR, NeurIPS), and AI Ethics (FAccT, AIES) conferences to see who was doing work that I was interested in. This meant that I was compiling a list of <u>professors</u> rather than <u>schools</u>, and I decided which progams to apply to based on which potential advisors I thought were interesting.</p>

<p>If you are already working with a professor on similar research to what you want to pursue during your PhD, then they can also be an invaluable resource for finding other faculty working on common topics.</p>

<p>It so happens that typically the “top” schools have the most faculty, which in turn means that they are more likely to have people working on what you’re interested in. I found this to be the case - according to most sources, I ended up applying to schools that were ranked in the top 50, with most in the top 20 or so in the US.</p>

<p>I considered applying to a couple of places outside of the US, but ultimately decided not to for a couple of reasons. One of these was simply that it was outside of my comfort zone, which is a completely valid reason not to apply/go somewhere when you’ll be spending a significant amount of time (likely 5-7 years) there.</p>

<p>Another caveat is that because I participated in an REU, I was able to get a fee waiver for many programs. This slightly lessened the cost burden of applying to 44 programs. Applying to 25 programs in a single year would likely be cost prohibitive to many people, and I understand that I was extremely privileged to get to shoot my shot at so many places.</p>

<p><b><u>The Statement of Purpose</u></b></p>

<!-- [My Statement](href="/assets/pdf/") -->

<p><a href="/assets/pdf/SOP_UW_pub.pdf" target="_blank" rel="noopener noreferrer">My Old Statement (2023-2024)</a> (for CSE, not InfoSci)</p>

<p><a href="/assets/pdf/Statement_of_Purpose_UW_pub.pdf" target="_blank" rel="noopener noreferrer">My New Statement (2024-2025)</a></p>

<p>In my opinion, the SOP is the most important aspect of your application that you have total control over. In fact, it’s one of the only parts of your application that you have complete control over.</p>

<p>To be completely candid (and perhaps to toot my own horn a bit), I’m a fairly strong writer. At the very least, I wasn’t intimidated by the SOP, and actually enjoyed writing it quite a lot. That being said, it’s likely a style of writing that’s relatively unfamiliar, and it takes some time for everyone to get it right. For the 2023-2024 cycle, I spent around three months writing and tweaking my statement; for 2024-2025, even though I had my statement from the previous cycle, as well as my GRFP materials, it still took me a couple of months to get it to a point where I was happy.</p>

<p>Other people have written ad nauseam about how to write the SOP, and honestly I don’t think I have any wisdom to share that hasn’t already been fleshed out by someone else. Like many before me, I heavily consulted <a href="https://cs-sop.notion.site/CS-PhD-Statements-of-Purpose-df39955313834889b7ac5411c37b958d">these statements</a> for stylistic choices. The big point to keep in mind is that the vast majority of people who have uploaded their materials come from privileged backgrounds and had many research opportunities (there is some selection bias - people who are willing to upload their materials are likely to have been successful in their research/applications). It’s easy to be intimidated by some of their profiles; try to keep in mind that everyone is on their own academic journey, and your application is just as valuable, even if it doesn’t look the same as some of the ones on the site.</p>

<p><b><u>The Personal Statement (or Diversity Statement)</u></b></p>

<p>I think in many cases the Personal/Diversity Statement is more intimidating than the Statement of Purpose. Not all schools require this statement, but if they do, it’s a good opportunity for you to demonstrate that you’re more than your research. A lot of people approach this statement as a way to demonstrate overcoming personal hardship, setbacks, etc. If you did face challenges in your academic career, then this is absolutely a place for you to discuss those barriers.</p>

<p>I didn’t experience much hardship in my academic journey, to be frank. I spent a lot of time thinking about what I would write about, and I read through a lot of information online discussing how to approach this statement. What I garnered ultimately is that this is a statement about <i>how your personal background will contribute environmentally to your field</i>. Not like trees environmentally, but rather how you can make your space in academia more inclusive, understanding, and open. This involves your contributions to the field, volunteering, mentorship, teaching, etc.</p>

<p>The iSchool at UW actually splits this statement into two separate ones. Honestly I don’t remember what the exact prompts were, but I’m including both of my statements here for reference.</p>

<p><a href="/assets/pdf/Personal_Statement_UW_pub.pdf" target="_blank" rel="noopener noreferrer">UW Personal Statement</a></p>

<p><a href="/assets/pdf/Diversity_Statement_UW_pub.pdf" target="_blank" rel="noopener noreferrer">UW Diversity Statement</a></p>

<p><b><u>The CV</u></b></p>

<p>Honestly not much to say here. Highlight your research experience and publications (if any) the most. Here’s the one I submitted to schools for reference:</p>

<p><a href="/assets/pdf/PhD_apps_CV.pdf" target="_blank" rel="noopener noreferrer">CV for PhD Applications</a></p>

<p><b><u>Interviews</u></b></p>

<p>Conventional wisdom online has previously said that for CS PhD programs, interviews are not always necessary. I think this is no longer true in the majority of cases (there are exceptions). There are way too many applicants now. When 10 people could fill one spot, interviews are probably necessary to distinguish between them beyond what’s on paper.</p>

<p>I interviewed with four programs in 2023-2024, and nine programs in 2024-2025. I wore a black mock neck shirt in all of them (no need to dress up). Most of these interviews were just conversations about research and interests, and trying to gauge whether there was a good fit with the lab. In one interview I had to prepare some slides to discuss both my previous research, and a prior publication from the professor. In another I was asked a couple of interesting theoretical questions to judge my mathematical reasoning and a bit of knowledge about the field. The vast majority though were simply discussing what research we found interesting, and looking for overlaps in potential new projects.</p>

<p>Oftentimes, the professor will tell you what to expect from the interview beforehand. It’s easy to say and hard to do, but try not to stress too much. In my first cycle, I was extremely nervous for all of my interviews. This past cycle, I eased up a lot and treated each one more as a friendly chat/discussion, and I think they went a lot better.</p>

<p>Here is the schedule of my interviews (some programs I interviewed more than once [often with different professors from the department], which accounts for the disparity in numbers from the above programs):</p>

<p>2023-2024:</p>
<ul>
  <li>1x January 12, 2024</li>
  <li>1x January 26, 2024</li>
  <li>1x January 30, 2024</li>
  <li>1x January 31, 2024</li>
  <li>1x February 16, 2024</li>
  <li>1x February 21, 2024</li>
</ul>

<p>2024-2025:</p>
<ul>
  <li>3x January 7, 2025</li>
  <li>1x January 9, 2025</li>
  <li>2x January 24, 2025</li>
  <li>1x January 30-31, 2025 (virtual visit style)</li>
  <li>1x February 6, 2025</li>
  <li>1x February 7, 2025</li>
  <li>1x February 10, 2025</li>
  <li>2x February 11, 2025</li>
  <li>1x February 12, 2025</li>
  <li>1x February 20, 2025</li>
  <li>1x February 26, 2025</li>
</ul>

<p>This year (2025), I also declined an interview on April 17th, as I had already accepted the offer at UW.</p>

<p>I didn’t receive a waitlist/offer from any program that I did not interview with.</p>

<h3><b>The NSF GRFP</b></h3>

<p>This year, I was also incredibly honored to have been awarded an NSF Graduate Research Fellowship. I applied during my gap year, so I would have had another chance to apply during either my first or second year of my PhD if I were not awarded the fellowship this year. The advice I’ve heard is that everyone should apply before starting grad school, and then as a second-year grad student if not awarded the first time. The reasoning I’ve heard for this is that the first application is essentially a freebie, and if you reapply as a second-year you’ll have had an extra year of research experience to bolster your application. That being said, I’ve also heard that each application is compared with other applications within its “level” (undergrad vs. undergrad, second-year vs. second-year). At the end of the day, asking your advisors or recommenders would be a better bet than just listening to me.</p>

<p>The best advice I would have for the GRFP is to read <a href="https://docs.google.com/spreadsheets/d/1xoezGhbtcpg3BvNdag2F5dTQM-Xl2EELUgAfG1eUg0s/edit?gid=0#gid=0">some examples</a>. I tried to read as many Personal Statements and Graduate Research Plans as I could to gauge how to successfully frame the Intellectual Merit and Broader Impacts sections. In fact, I personally think I may have read <i>too many</i>, as they were all different enough that I got stuck trying to format my statements. 2-3 awarded examples may be a good balance.</p>

<p>My own materials were by no means perfect, and each time I read through now I find something that I would want to change. Such is the reality of writing. I was quite happy with the formatting though and largely with the articulation of my background and ideas. Here are the statements that I ended up submitting:</p>

<p><a href="/assets/pdf/GRFP_Personal_Statement_Final.pdf" target="_blank" rel="noopener noreferrer">My Personal Statement</a></p>

<p><a href="/assets/pdf/GRFP_Graduate_Research_Plan_Final.pdf" target="_blank" rel="noopener noreferrer">My Graduate Research Plan</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[lessons I learned from applying for graduate school]]></summary></entry></feed>